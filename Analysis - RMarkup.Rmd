---
title: "Predicting Housing Sale Prices in Ames, Iowa"
output:
  html_document:
    df_print: paged
---

Project Description
With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, our goal is to predict the final price of each home of the test data set using the training data set.

Datasets
80 Columns x 1460 Rows of housing sales data from years 2006 to 2010

Source: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

Load and print structure of pricing data
```{r}
data <- read.csv(file = 'data.csv',
                 header = TRUE, 
                 sep = ",",
                 stringsAsFactors = FALSE)
str(data)
```

Select non object columns (and Set NA to 0)
For purposes of this exercise use only numeric variables (treat as continuous)
```{r}
df <- data[, sapply(data, class) != "character"]
df[is.na(df)] <- 0
str(df)
```

One-way plots
Graphs target variable (SalePrice) vs each independent variable
First 9 variables excluding Id
```{r}
nplots <- seq(from=2, to=10, by=1)

par(mfrow=c(3,3))

for (i in nplots) {
  plot(df[,i], df[,38], xlab=colnames(df)[i], ylab=colnames(df)[38])
}
```

Graphs target variable (SalePrice) vs each independent variable
11-19 variables excluding Id
```{r}
nplots <- seq(from=11, to=19, by=1)

par(mfrow=c(3,3))

for (i in nplots) {
  plot(df[,i], df[,38], xlab=colnames(df)[i], ylab=colnames(df)[38])
}
```

Graphs target variable (SalePrice) vs each independent variable
20-28 variables excluding Id
```{r}
nplots <- seq(from=20, to=28, by=1)

par(mfrow=c(3,3))

for (i in nplots) {
  plot(df[,i], df[,38], xlab=colnames(df)[i], ylab=colnames(df)[38])
}
```

Graphs target variable (SalePrice) vs each independent variable
29-37 variables excluding Id
```{r}
nplots <- seq(from=29, to=37, by=1)

par(mfrow=c(3,3))

for (i in nplots) {
  plot(df[,i], df[,38], xlab=colnames(df)[i], ylab=colnames(df)[38])
}
```

Initial Modeling and Variable Selection

Single Variable Model 
```{r}
i = 2
frm <- as.formula(paste("SalePrice ~ 0 + ", colnames(data)[i]))
fit <- glm(formula = frm, data=df, family = gaussian())
summary(fit)
```

Ordinary least squares - Single variable - Calculates the Deviance
```{r}
nums <- seq(from=1, to=37, by=1)
fields <- character()
dev <- double()

for (i in nums) {
  f <- colnames(df)[i]
  fields[i] <- f
  frm <- as.formula(paste("SalePrice ~ 0 + ", f))
  fit <- glm(formula = frm, data=df, family = gaussian())
  dev[i] <- summary(fit)$deviance
}

devs <- data.frame(fields= fields, dev = dev)
devs <- devs[order(devs$dev),]
devs[1:15,]
```

Selected independent variables - Normalize (Min/Max)
```{r}
cols <- c(
 'LotArea',
 'OverallQual',
 'OverallCond',
 'YearBuilt',
 'TotalBsmtSF',
 'X1stFlrSF',
 'GrLivArea',
 'FullBath',
 'GarageCars',
 'WoodDeckSF'
)

X <- data[,cols]

for (f in colnames(X)) {
 X[f] = (X[f] - min(X[f])) / (max(X[f]) - min(X[f]))
}

str(X)
```

Calculate correlation between fields
```{r}
corr = cor(X)
round(corr,3)
```

Fit model to selected data
```{r}
X["SalePrice"] = data["SalePrice"]

fit <- glm(formula = "SalePrice ~ .", data=X, family = gaussian())
summary(fit)
```

Reselected independent variables
```{r}
cols <- c(
 'LotArea',
 'OverallQual',
 'OverallCond',
 'YearBuilt',
 'TotalBsmtSF',
 
 'GrLivArea',
 
 'GarageCars',
 'WoodDeckSF'
)

X <- data[,cols]

for (f in colnames(X)) {
 X[f] = (X[f] - min(X[f])) / (max(X[f]) - min(X[f]))
}

str(X)
```

Calculate correlation between fields
```{r}
corr = cor(X)
round(corr,3)
```

Rerun model
```{r}
X["SalePrice"] = data["SalePrice"]

fit <- glm(formula = "SalePrice ~ .", data=X, family = gaussian())
summary(fit)
```

Histogram of Sale Price
```{r}
hist(data$SalePrice, breaks=30)
```

# Create a train and test data set
```{r}
set.seed(11)   
sample <- sample.int(n = nrow(X), size = floor(0.7*nrow(X)), replace = F)
train <- X[sample, ]
test  <- X[-sample, ]
str(train)
```

Models: link function Identity and Log
```{r}
model_ind <- glm(formula = "SalePrice ~ .", data=train, family = gaussian())
summary(model_ind)

model_log <- glm(formula = "SalePrice ~ .", data=train, family = gaussian(link="log"))
summary(model_log)
```
Plots - Actual vs Predicted - Train Dataset
```{r}
pred_ind <- predict(model_ind, train, type = "response")
pred_log <- predict(model_log, train, type = "response")

par(mfrow=c(1,2))
plot(pred_ind, as.numeric(train$SalePrice),col="blue")
points(pred_log, as.numeric(train$SalePrice),col="red")
abline(a=0,b=1,col="black")

plot(sort(pred_ind), sort(as.numeric(train$SalePrice)),col="blue")
points(sort(pred_log), sort(as.numeric(train$SalePrice)),col="red")
abline(a=0,b=1,col="black")
```

Plots - Actual vs Predicted - Test Dataset
```{r}
pred_ind_test <- predict(model_ind, test, type = "response")
pred_log_test <- predict(model_log, test, type = "response")

par(mfrow=c(1,2))
plot(pred_ind, as.numeric(train$SalePrice),col="blue")
points(pred_log, as.numeric(train$SalePrice),col="red")
abline(a=0,b=1,col="black")

plot(sort(pred_ind), sort(as.numeric(train$SalePrice)),col="blue")
points(sort(pred_log), sort(as.numeric(train$SalePrice)),col="red")
abline(a=0,b=1,col="black")
```

Calculate the sqrt (mean squared error)
```{r}
mse = mean((pred_log - as.numeric(train$SalePrice))^2) ^ 0.5
avg = mean(as.numeric(train$SalePrice))
paste("Train Data - MSE: ", format(round(mse,2),big.mark=",",decimal.mark="."), " and Mean Value: ", format(round(avg,2),big.mark=",",decimal.mark="."))


mse = mean((pred_log_test - as.numeric(test$SalePrice))^2) ^ 0.5
avg = mean(as.numeric(test$SalePrice))
paste("Train Data - MSE: ", format(round(mse,2),big.mark=",",decimal.mark="."), " and Mean Value: ", format(round(avg,2),big.mark=",",decimal.mark="."))
```
